---
dg-publish: true
description: Contrastive Language-Image Pre-training (CLIP) is a computer vision model developed by OpenAI that has the ability to understand and process image and text data simultaneously. The core idea behind CLIP is to learn the relationships between images extracted from large datasets and the text describing them.
---
#[[Projects/Library/500/500\|500]]#ML_and_DL_Modeling#[[Projects/Library/500/520/520\|520]]#Computer_Vision#[[Projects/Library/500/520/520.30/520.30\|520.30]]#Generative_Models_in_CV#[[Projects/Library/500/520/520.30/520.30 b\|520.30 b]]#CLIP


